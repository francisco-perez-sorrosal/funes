{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 14,\n",
       " 'functions': None,\n",
       " 'config_list': [{'model': 'gpt-4o-mini',\n",
       "   'api_key': ''}],\n",
       " 'temperature': 0.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from funes.agents.agent_types import Role, Persona, AutogenAgentType\n",
    "from llm_foundation import logger\n",
    "from llm_foundation.basic_structs import Provider, LMConfig\n",
    "from pprint import pprint\n",
    "import tempfile\n",
    "\n",
    "import autogen\n",
    "from autogen.coding import LocalCommandLineCodeExecutor, DockerCommandLineCodeExecutor\n",
    "from autogen.agentchat import GroupChat, GroupChatManager\n",
    "\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "lm_config = LMConfig(model=\"gpt-4o-mini\", provider=Provider.Autogen)\n",
    "llm_config = lm_config.to_autogen()\n",
    "llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona: Francisco\n",
      "  Role: learner\n",
      "  Description: A highly motivated human that is eager to learn.\n",
      "  Agent System Message: A human admin. Reply TERMINATE when the task is done.\n",
      "  Autogen Code Execution Config: {}\n",
      " Persona: Ian_Robinson\n",
      "  Role: neo4j\n",
      "  Description: An expert in graph databases and Cypher query language in particular.\n",
      "  Agent System Message: You are an expert in generating the most flexible queries in Cypher language to serve the user requests. You will receive json objects that will encode nodes, keys and relationships in a Cypher knowledge graph. You will identify if the current graph has already present concepts and keys that you can reuse them to generate the partial graph structures encoding the json information, e.g. if the graph has a Person node integrate an Author as a person that has a property author in a relationship WROTE. Name all nodes and relationships (e.g. MERGE (a)-[wrote:WROTE]->(b)). Reply only with the Cypher queries and RETURN statements with the affected nodes and relationships, but without any wrappers nor bat-ticks. Reply TERMINATE when the task is done.\n",
      "  Autogen Code Execution Config: {}\n",
      "  Role: neo4j_tool_whisperer\n",
      "  Description: You are a helpful AI assistant.\n",
      "  Agent System Message: You can help getting the function signatures to call tools related to Neo4j Cypher queries.\n",
      "  Autogen Code Execution Config: {}\n",
      "  Role: neo4j_python_dev\n",
      "  Description: You are a helpful neo4j code assistant and developer.\n",
      "  Agent System Message: You are a helpful AI code assistant expert in neo4j python libraries. You will receive Cypher queries representing a graph structure and you will provide python code to execute them using your combined coding and language skills in python and Cypher. In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. 1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself. 2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill. When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user. If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible. Some environment variables can be read from a .env file. Reply 'TERMINATE' in the end when everything is done.\n",
      "  Autogen Code Execution Config: {}\n",
      "  Role: neo4j_code_executor\n",
      "  Description: N/A\n",
      "  Agent System Message: N/A\n",
      "  Autogen Code Execution Config: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "francisco = Persona.from_json_file(\"Persona/Francisco.json\")\n",
    "neo4j_persona = Persona.from_json_file(\"Persona/Neo4jExpert.json\")\n",
    "print(francisco, neo4j_persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = os.environ[\"NEO4J_URI\"]\n",
    "NEO4J_USERNAME = os.environ[\"NEO4J_USERNAME\"]\n",
    "NEO4J_PASSWORD = os.environ[\"NEO4J_PASSWORD\"]\n",
    "NEO4J_DATABASE = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.graphs.neo4j_graph.Neo4jGraph'>\n"
     ]
    }
   ],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")\n",
    "\n",
    "print(type(kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_props': {'Person': [{'property': 'name', 'type': 'STRING'},\n",
       "   {'property': 'last_name', 'type': 'STRING'},\n",
       "   {'property': 'birth_date', 'type': 'STRING'}],\n",
       "  'Author': [{'property': 'name', 'type': 'STRING'}],\n",
       "  'Book': [{'property': 'year', 'type': 'STRING'},\n",
       "   {'property': 'isbn', 'type': 'STRING'},\n",
       "   {'property': 'title', 'type': 'STRING'},\n",
       "   {'property': 'url', 'type': 'STRING'}],\n",
       "  'Publisher': [{'property': 'name', 'type': 'STRING'}]},\n",
       " 'rel_props': {},\n",
       " 'relationships': [{'start': 'Person', 'type': 'sibling', 'end': 'Person'},\n",
       "  {'start': 'Person', 'type': 'WROTE', 'end': 'Book'},\n",
       "  {'start': 'Author', 'type': 'WROTE', 'end': 'Book'},\n",
       "  {'start': 'Book', 'type': 'PUBLISHED_BY', 'end': 'Publisher'}],\n",
       " 'metadata': {'constraint': [], 'index': []}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.get_structured_schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "CREATE (a:Author {name: 'Sebastian Raschka'}),\\n       (b:Book {title: 'Build A Large Language Model (From Scratch)', year: '2024', isbn: '978-1633437166', url: 'https://www.manning.com/books/build-a-large-language-model-from-scratch'}),\\n       (p:Publisher {name: 'Manning'}),\\n       (a)-[:WROTE]->(b),\\n       (b)-[:PUBLISHED_BY]->(p);\\n\n",
    "\"\"\"\n",
    "\n",
    "result = kg.query(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Nodes\n",
      "['Person', 'Author', 'Book', 'Publisher']\n",
      "['name', 'last_name', 'birth_date']\n",
      "Graph Edges\n",
      "All: (['sibling', 'WROTE', 'WROTE', 'PUBLISHED_BY'], [{'start': 'Person', 'type': 'sibling', 'end': 'Person'}, {'start': 'Person', 'type': 'WROTE', 'end': 'Book'}, {'start': 'Author', 'type': 'WROTE', 'end': 'Book'}, {'start': 'Book', 'type': 'PUBLISHED_BY', 'end': 'Publisher'}])\n",
      "Person-as-origin: (['sibling', 'WROTE'], [{'start': 'Person', 'type': 'sibling', 'end': 'Person'}, {'start': 'Person', 'type': 'WROTE', 'end': 'Book'}])\n",
      "Person-as-end: (['sibling'], [{'start': 'Person', 'type': 'sibling', 'end': 'Person'}])\n",
      "Book-as-origin: (['PUBLISHED_BY'], [{'start': 'Book', 'type': 'PUBLISHED_BY', 'end': 'Publisher'}])\n",
      "Book-as-end: (['WROTE', 'WROTE'], [{'start': 'Person', 'type': 'WROTE', 'end': 'Book'}, {'start': 'Author', 'type': 'WROTE', 'end': 'Book'}])\n",
      "Person-Book: (['WROTE'], [{'start': 'Person', 'type': 'WROTE', 'end': 'Book'}])\n",
      "Graph Francisco Node Instances\n",
      "All instances: [{'person': {'birth_date': '1976/06/14', 'name': 'Francisco', 'last_name': 'Perez-Sorrosal'}}, {'person': {'birth_date': '1976/06/16', 'name': 'Francisco', 'last_name': 'Lopez'}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from abc import ABC\n",
    "from typing import List, Optional\n",
    "from langchain_community.graphs.neo4j_graph import Neo4jGraph\n",
    "\n",
    "\n",
    "class GraphMetadata(ABC):\n",
    "    \n",
    "    def __init__(self, graph: Neo4jGraph):\n",
    "        self.graph = graph\n",
    "        self.schema = self.graph.get_structured_schema\n",
    "\n",
    "    def get_node_names(self) -> List[str]:\n",
    "        nodes = self.schema[\"node_props\"]\n",
    "        return list(nodes.keys())\n",
    "\n",
    "    def get_edge_names(self, origin: Optional[str] = None, dest: Optional[str] = None):\n",
    "        \n",
    "        def filter_edges_on_prop(edges, prop_id, value):\n",
    "            return [edge for edge in edges if edge[prop_id] == value]\n",
    "        \n",
    "        nodes = self.schema[\"relationships\"]\n",
    "        \n",
    "        if origin is not None:\n",
    "            nodes = filter_edges_on_prop(nodes, \"start\", origin)\n",
    "\n",
    "        if dest is not None:\n",
    "            nodes = filter_edges_on_prop(nodes, \"end\", dest)\n",
    "        \n",
    "        return [node['type'] for node in nodes], nodes\n",
    "\n",
    "    def is_node_in_graph(self, node: str):\n",
    "        nodes = self.get_node_names()\n",
    "        return node in nodes\n",
    "\n",
    "    def get_node_attributes_from_node(self, node):\n",
    "        attributes = []\n",
    "        if self.is_node_in_graph(node):\n",
    "            attributes = [property_info[\"property\"] for property_info in self.schema[\"node_props\"][node]]\n",
    "        return attributes\n",
    "\n",
    "    def get_node_instance(self, node: str, instance_id: str, instance_name: str):\n",
    "\n",
    "        res = \"\"        \n",
    "        if self.is_node_in_graph(node):\n",
    "            query_node_id = f\"{node.lower()}\"\n",
    "            res = self.graph.query(f\"\"\"\n",
    "                          MATCH ({query_node_id}:{node}) \n",
    "                          WHERE {query_node_id}.{instance_id} = '{instance_name}' \n",
    "                          RETURN {query_node_id}\n",
    "                          \"\"\")\n",
    "        return res\n",
    "\n",
    "graph_metadata = GraphMetadata(kg)\n",
    "\n",
    "\n",
    "class GetNodeNames(BaseTool):\n",
    "    name = \"get_node_names\"\n",
    "    description = \"Extract node names from a graph\"\n",
    "    # args_schema: Type[BaseModel] = SearchToolInput\n",
    "    graph: GraphMetadata\n",
    "\n",
    "    def _run(self):\n",
    "        return self.graph.get_node_names()\n",
    "    \n",
    "class GetRelationshipNames(BaseTool):\n",
    "    name = \"get_relationship_names\"\n",
    "    description = \"Extract relationship names from a graph\"\n",
    "    # args_schema: Type[BaseModel] = SearchToolInput\n",
    "    graph: GraphMetadata\n",
    "\n",
    "    def _run(self):\n",
    "        return self.graph.get_edge_names()\n",
    "        \n",
    "\n",
    "get_node_names = GetNodeNames(graph=graph_metadata)\n",
    "get_relationship_names = GetRelationshipNames(graph=graph_metadata)\n",
    "\n",
    "# Get graph nodes \n",
    "print(\"Graph Nodes\")\n",
    "print(graph_metadata.get_node_names())\n",
    "print(graph_metadata.get_node_attributes_from_node(\"Person\"))\n",
    "\n",
    "# Get edges\n",
    "print(\"Graph Edges\")\n",
    "print(f\"All: {graph_metadata.get_edge_names()}\")\n",
    "print(f\"Person-as-origin: {graph_metadata.get_edge_names('Person')}\")\n",
    "print(f\"Person-as-end: {graph_metadata.get_edge_names(None, 'Person')}\")\n",
    "print(f\"Book-as-origin: {graph_metadata.get_edge_names('Book')}\")\n",
    "print(f\"Book-as-end: {graph_metadata.get_edge_names(None, 'Book')}\")\n",
    "print(f\"Person-Book: {graph_metadata.get_edge_names('Person', 'Book')}\")\n",
    "\n",
    "# Get graph node instances\n",
    "print(\"Graph Francisco Node Instances\")\n",
    "print(f\"All instances: {graph_metadata.get_node_instance('Person', 'name', 'Francisco')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 09-28 00:01:14] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:14 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 09-28 00:01:14] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:14 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 09-28 00:01:14] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:14 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 09-28 00:01:14] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:14 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mlearner\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Get an accurate Cypher query to encode the information on the following json object. \n",
      "Then, make a python program to execute in neo4j. \n",
      "Execute the program, fixing any errors that may arise. \n",
      "The NEO4J_USERNAME, NEO4J_PASSWORD and NEO4J_URI environment variables can be read from a .env file in the current dir.\n",
      "\n",
      "{'title': 'AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation', 'authors': ['Qingyun Wu', 'Gagan Bansal', 'Jieyu Zhang', 'Yiran Wu', 'Beibin Li', 'Erkang Zhu', 'Li Jiang', 'Xiaoyun Zhang', 'Shaokun Zhang', 'Jiale Liu', 'Ahmed H Awadallah', 'Ryen White', 'Doug Burger', 'Chi Wang'], 'publish_date': 'September 25, 2023', 'conference': 'Workshop on Large Language Models for Agents', 'uri': 'https://arxiv.org/abs/2308.08155'}\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: neo4j\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:16 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mneo4j\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function call: get_node_names *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m***************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: neo4j\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_node_names...\u001b[0m\n",
      "\u001b[33mneo4j\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function (get_node_names) *****\u001b[0m\n",
      "['Person', 'Author', 'Book', 'Publisher']\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 09-28 00:01:16] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:16 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mchecking_agent\u001b[0m (to speaker_selection_agent):\n",
      "\n",
      "Read the above conversation. Then select the next role from ['neo4j_python_dev', 'learner'] to play. Only return the role.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:16 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mspeaker_selection_agent\u001b[0m (to checking_agent):\n",
      "\n",
      "neo4j_python_dev\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m>>>>>>>> Select speaker attempt 1 of 3 successfully selected: neo4j_python_dev\u001b[0m\n",
      "\u001b[32m\n",
      "Next speaker: neo4j_python_dev\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:17 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mneo4j_python_dev\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function call: get_relationship_names *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: neo4j\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_relationship_names...\u001b[0m\n",
      "\u001b[33mneo4j\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function (get_relationship_names) *****\u001b[0m\n",
      "(['sibling', 'WROTE', 'WROTE', 'PUBLISHED_BY'], [{'start': 'Person', 'type': 'sibling', 'end': 'Person'}, {'start': 'Person', 'type': 'WROTE', 'end': 'Book'}, {'start': 'Author', 'type': 'WROTE', 'end': 'Book'}, {'start': 'Book', 'type': 'PUBLISHED_BY', 'end': 'Publisher'}])\n",
      "\u001b[32m*******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 09-28 00:01:17] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:17 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mchecking_agent\u001b[0m (to speaker_selection_agent):\n",
      "\n",
      "Read the above conversation. Then select the next role from ['neo4j_python_dev', 'learner'] to play. Only return the role.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:17 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mspeaker_selection_agent\u001b[0m (to checking_agent):\n",
      "\n",
      "neo4j_python_dev\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m>>>>>>>> Select speaker attempt 1 of 3 successfully selected: neo4j_python_dev\u001b[0m\n",
      "\u001b[32m\n",
      "Next speaker: neo4j_python_dev\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:26 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mneo4j_python_dev\u001b[0m (to chat_manager):\n",
      "\n",
      "To encode the provided JSON object into a Neo4j graph, we will create nodes for the book and its authors, and establish relationships between them. The Cypher query will create a `Book` node and `Author` nodes, and link them with the `WROTE` relationship.\n",
      "\n",
      "Here’s the plan:\n",
      "1. Create a `Book` node with properties from the JSON object.\n",
      "2. Create `Author` nodes for each author in the list.\n",
      "3. Create `WROTE` relationships between the `Book` node and each `Author` node.\n",
      "\n",
      "Now, I will write a Python program to execute this in Neo4j. The program will read the environment variables from a `.env` file, connect to the Neo4j database, and execute the Cypher query.\n",
      "\n",
      "Here is the complete Python code:\n",
      "\n",
      "```python\n",
      "# filename: encode_book.py\n",
      "import os\n",
      "from dotenv import load_dotenv\n",
      "from neo4j import GraphDatabase\n",
      "\n",
      "# Load environment variables from .env file\n",
      "load_dotenv()\n",
      "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
      "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
      "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
      "\n",
      "# JSON object\n",
      "data = {\n",
      "    'title': 'AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation',\n",
      "    'authors': ['Qingyun Wu', 'Gagan Bansal', 'Jieyu Zhang', 'Yiran Wu', 'Beibin Li', \n",
      "                'Erkang Zhu', 'Li Jiang', 'Xiaoyun Zhang', 'Shaokun Zhang', 'Jiale Liu', \n",
      "                'Ahmed H Awadallah', 'Ryen White', 'Doug Burger', 'Chi Wang'],\n",
      "    'publish_date': 'September 25, 2023',\n",
      "    'conference': 'Workshop on Large Language Models for Agents',\n",
      "    'uri': 'https://arxiv.org/abs/2308.08155'\n",
      "}\n",
      "\n",
      "# Connect to Neo4j\n",
      "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
      "\n",
      "def create_book_and_authors(tx, data):\n",
      "    # Cypher query to create the book and authors\n",
      "    query = \"\"\"\n",
      "    CREATE (b:Book {title: $title, publish_date: $publish_date, conference: $conference, uri: $uri})\n",
      "    WITH b\n",
      "    UNWIND $authors AS authorName\n",
      "    MERGE (a:Author {name: authorName})\n",
      "    CREATE (a)-[:WROTE]->(b)\n",
      "    \"\"\"\n",
      "    tx.run(query, title=data['title'], publish_date=data['publish_date'], \n",
      "            conference=data['conference'], uri=data['uri'], authors=data['authors'])\n",
      "\n",
      "# Execute the transaction\n",
      "with driver.session() as session:\n",
      "    session.write_transaction(create_book_and_authors, data)\n",
      "\n",
      "# Close the driver\n",
      "driver.close()\n",
      "```\n",
      "\n",
      "Please save the above code in a file named `encode_book.py` and execute it. This will create the necessary nodes and relationships in your Neo4j database.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: neo4j_code_executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "\u001b[33mneo4j_code_executor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: /tmp/tmpraf5383s/encode_book.py:40: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(create_book_and_authors, data)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 09-28 00:01:28] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:28 fperez-gcloud-stupid-sailor-twift autogen.oai.client[4101110] WARNING The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mchecking_agent\u001b[0m (to speaker_selection_agent):\n",
      "\n",
      "Read the above conversation. Then select the next role from ['neo4j_python_dev', 'learner'] to play. Only return the role.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:28 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mspeaker_selection_agent\u001b[0m (to checking_agent):\n",
      "\n",
      "learner\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m>>>>>>>> Select speaker attempt 1 of 3 successfully selected: learner\u001b[0m\n",
      "\u001b[32m\n",
      "Next speaker: learner\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:30 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mlearner\u001b[0m (to chat_manager):\n",
      "\n",
      "The Python program executed successfully, and the data has been encoded into the Neo4j database. However, there is a deprecation warning indicating that `write_transaction` has been renamed to `execute_write`. \n",
      "\n",
      "To address this, you can update the code as follows:\n",
      "\n",
      "```python\n",
      "# Replace this line\n",
      "# session.write_transaction(create_book_and_authors, data)\n",
      "\n",
      "# With this line\n",
      "session.execute_write(create_book_and_authors, data)\n",
      "```\n",
      "\n",
      "Make this change in your code, and it will be aligned with the latest Neo4j Python driver conventions.\n",
      "\n",
      "If you need any further assistance or modifications, let me know! \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: neo4j\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 00:01:30 fperez-gcloud-stupid-sailor-twift httpx[4101110] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mneo4j\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "!rm -rf .cache\n",
    "\n",
    "get_node_names_tool = convert_to_openai_function(get_node_names)\n",
    "get_relationship_names_tool = convert_to_openai_function(get_relationship_names)\n",
    "\n",
    "tools = [get_node_names_tool, get_relationship_names_tool]\n",
    "llm_with_tools_config = llm_config.copy()\n",
    "llm_with_tools_config.update({\"functions\": tools})\n",
    "\n",
    "\n",
    "\n",
    "neo4j_agent = neo4j_persona.role_to_autogen_agent(\"neo4j\", AutogenAgentType.AssistantAgent, llm_config=llm_with_tools_config)\n",
    "# neo4j_agent.register_for_execution(name=\"get_node_names\")(get_node_names._run)\n",
    "neo4j_agent.register_function(\n",
    "    function_map={\n",
    "        get_node_names.name: get_node_names._run,\n",
    "        get_relationship_names.name: get_relationship_names._run,\n",
    "    })\n",
    "\n",
    "\n",
    "# This guy just writes code\n",
    "neo4j_python_dev_agent = neo4j_persona.role_to_autogen_agent(\"neo4j_python_dev\", AutogenAgentType.AssistantAgent, llm_config=llm_with_tools_config, code_execution_config=False)\n",
    "\n",
    "\n",
    "# Create a local command line code executor.\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "neo4j_code_executor_agent = neo4j_persona.role_to_autogen_agent(\"neo4j_code_executor\", AutogenAgentType.AssistantAgent, llm_config=False, code_execution_config={\"executor\": executor})\n",
    "\n",
    "francisco_learner = francisco.role_to_autogen_agent(\"learner\", AutogenAgentType.UserProxyAgent, \"NEVER\", llm_config=llm_config, termination_function=lambda msg: \"terminate\" in msg[\"content\"].lower(),)\n",
    "\n",
    "agent_speaker_transitions_dict = {\n",
    "    francisco_learner: [neo4j_agent],\n",
    "    neo4j_agent: [francisco_learner, neo4j_python_dev_agent],\n",
    "    neo4j_python_dev_agent: [neo4j_code_executor_agent],\n",
    "    neo4j_code_executor_agent: [neo4j_python_dev_agent, francisco_learner]\n",
    "}\n",
    "\n",
    "groupchat = GroupChat(\n",
    "    agents = [neo4j_agent, neo4j_python_dev_agent, neo4j_code_executor_agent, francisco_learner],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    select_speaker_auto_verbose=True,\n",
    "    speaker_transitions_type=\"allowed\",  # This has to be specified if the transitions below apply\n",
    "    allowed_or_disallowed_speaker_transitions=agent_speaker_transitions_dict,\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(\n",
    "    groupchat=groupchat, \n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You act as a coordinator for different specialiced roles. If you don't have anything to say, just say TERMINATE.\"\n",
    ")        \n",
    "\n",
    "\n",
    "book_json = {\n",
    "    \"author\": \"Sebastian Raschka\",\n",
    "    \"title\": \"Build A Large Language Model (From Scratch)\",\n",
    "    \"publisher\": \"Manning\",\n",
    "    \"year\": \"2024\",\n",
    "    \"isbn\": \"978-1633437166\",\n",
    "    \"url\": \"https://www.manning.com/books/build-a-large-language-model-from-scratch\"\n",
    "}\n",
    "\n",
    "book_json = {\n",
    "  \"title\": \"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation\",\n",
    "  \"authors\": [\n",
    "    \"Qingyun Wu\",\n",
    "    \"Gagan Bansal\",\n",
    "    \"Jieyu Zhang\",\n",
    "    \"Yiran Wu\",\n",
    "    \"Beibin Li\",\n",
    "    \"Erkang Zhu\",\n",
    "    \"Li Jiang\",\n",
    "    \"Xiaoyun Zhang\",\n",
    "    \"Shaokun Zhang\",\n",
    "    \"Jiale Liu\",\n",
    "    \"Ahmed H Awadallah\",\n",
    "    \"Ryen White\",\n",
    "    \"Doug Burger\",\n",
    "    \"Chi Wang\"\n",
    "  ],\n",
    "  \"publish_date\": \"September 25, 2023\",\n",
    "  \"conference\": \"Workshop on Large Language Models for Agents\",\n",
    "  \"uri\": \"https://arxiv.org/abs/2308.08155\"    \n",
    "}\n",
    "\n",
    "content = f\"\"\"\n",
    "Get an accurate Cypher query to encode the information on the following json object. \n",
    "Then, make a python program to execute in neo4j. \n",
    "Execute the program, fixing any errors that may arise. \n",
    "The NEO4J_USERNAME, NEO4J_PASSWORD and NEO4J_URI environment variables can be read from a .env file in the current dir.\n",
    "\n",
    "{book_json}\n",
    "\"\"\"\n",
    "\n",
    "response = francisco_learner.initiate_chat(\n",
    "    manager,\n",
    "    message={\"content\": content, \"role\": \"user\"},\n",
    ")\n",
    "\n",
    "\n",
    "def find_last_message(name: str, chat_history):\n",
    "    for message in reversed(chat_history):\n",
    "        if message[\"name\"] == name:\n",
    "            return message\n",
    "    return None\n",
    "\n",
    "print(find_last_message(\"neo4j\", response.chat_history)[\"content\"])\n",
    "\n",
    "\n",
    "# francisco_learner.initiate_chat(neo4j_agent, message=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "user = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Create a Neo4j driver\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "book_json = {\n",
    "    \"author\": \"Sebastian Raschka\",\n",
    "    \"title\": \"Build A Large Language Model (From Scratch)\",\n",
    "    \"publisher\": \"Manning\",\n",
    "    \"year\": \"2024\",\n",
    "    \"isbn\": \"978-1633437166\",\n",
    "    \"url\": \"https://www.manning.com/books/build-a-large-language-model-from-scratch\"\n",
    "}\n",
    "\n",
    "\n",
    "content = f\"\"\"\n",
    "Given the following json object about a book release, identify the main entities and relationships to build a graph encoded with nodes and relationships\n",
    "with Cypher language. Name all nodes and relationships (e.g. MERGE (a)-[wrote:WROTE]->(b)). Check also first if the graph contains a high level entity \n",
    "for some of the new entities identified and try to integrate better the new subgraph (e.g. if the graph has a Person node integrate an Author as a person\n",
    "that has a property author in a relationship WROTE). Reply only with the Cypher queries and RETURN statements with the affected \n",
    "nodes and relationships, but without any wrappers nor bat-ticks.\n",
    "\n",
    "{book_json}\n",
    "\"\"\"\n",
    "\n",
    "print(content)\n",
    "\n",
    "resp = francisco_learner.generate_reply(\n",
    "    messages=[{\"content\": content, \"role\": \"user\"}]\n",
    ")\n",
    "\n",
    "pprint(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = f\"\"\"\n",
    "Given the following Cypher query, identify if the current graph contains a high level entity \n",
    "for some of the new entities identified in the query and try to use them in the new subgraph (e.g. check if the graph has a IndividualContributor node \n",
    "and in the query there has been identified an Boss, rewrite the query to use Person as node and integrate the author as a property\n",
    "of a possible relationship MANAGES). Name all nodes and relationships (e.g. MERGE (a)-[wrote:WROTE]->(b)) Reply only with the rewriten Cypher queries and RETURN statements with the affected nodes and \n",
    "relationships, but without any wrappers nor bat-ticks.\n",
    "\n",
    "{resp}\n",
    "\"\"\"\n",
    "\n",
    "print(content)\n",
    "\n",
    "resp_rewrite = francisco_learner.generate_reply(\n",
    "    messages=[{\"content\": content, \"role\": \"user\"}]\n",
    ")\n",
    "\n",
    "pprint(resp_rewrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kg.query(resp)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "funes-pixi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
